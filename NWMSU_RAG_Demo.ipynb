{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéì Build Your Own RAG Chatbot for NWMSU MS-ACS Program\n",
        "\n",
        "## Complete Step-by-Step Tutorial for Students\n",
        "\n",
        "This notebook will guide you through building a complete RAG (Retrieval-Augmented Generation) chatbot for Northwest Missouri State University's MS-ACS program. You'll learn how to create a chatbot that provides context to AI models before answering questions.\n",
        "\n",
        "### üéØ What You'll Learn:\n",
        "- **RAG Architecture**: How retrieval and generation work together\n",
        "- **Context Retrieval**: How to find relevant information before answering\n",
        "- **Vector Embeddings**: Convert text to numerical representations\n",
        "- **LangChain Framework**: Modern tools for building LLM applications\n",
        "- **Interactive Chatbot**: Create a working chatbot interface\n",
        "\n",
        "### üöÄ Final Goal:\n",
        "Build a complete RAG chatbot that can answer questions about the NWMSU MS-ACS program by retrieving relevant context from the university's website.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Step 1: Setup and Installation\n",
        "\n",
        "Let's start by installing all the required packages for our RAG chatbot. This will take a few minutes as we download the necessary libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages for our RAG chatbot\n",
        "print(\"üì¶ Installing packages... This may take a few minutes.\")\n",
        "\n",
        "# Core RAG packages\n",
        "!pip install -q langchain==0.1.0 langchain-community==0.0.10 langchain-core==0.1.0\n",
        "\n",
        "# AI/ML packages\n",
        "!pip install -q sentence-transformers==5.1.1 transformers==4.57.1 torch==2.8.0\n",
        "\n",
        "# Web scraping and data processing\n",
        "!pip install -q requests beautifulsoup4 lxml\n",
        "\n",
        "# Interactive widgets for our chatbot interface\n",
        "!pip install -q ipywidgets\n",
        "\n",
        "# Optional: Neo4j for advanced features (we'll use FAISS for simplicity)\n",
        "!pip install -q faiss-cpu\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")\n",
        "print(\"üéâ Ready to build your RAG chatbot!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Step 2: Import Libraries\n",
        "\n",
        "Now let's import all the libraries we need to build our RAG chatbot. These libraries will help us with:\n",
        "- **LangChain**: Framework for building LLM applications\n",
        "- **Transformers**: AI models for text processing\n",
        "- **FAISS**: Vector database for similarity search\n",
        "- **Web scraping**: Get data from NWMSU website\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all the libraries we need for our RAG chatbot\n",
        "import os\n",
        "import warnings\n",
        "import time\n",
        "from typing import List, Tuple\n",
        "import re\n",
        "\n",
        "# LangChain - Our main framework for building the chatbot\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# AI/ML libraries\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "import torch\n",
        "\n",
        "# Interactive interface for our chatbot\n",
        "from IPython.display import display, HTML, Markdown\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(\"üöÄ Ready to start building your RAG chatbot!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Step 3: Build Your RAG Chatbot Class\n",
        "\n",
        "Now we'll create the main class for our RAG chatbot. This class will handle:\n",
        "- **Data Loading**: Get information from NWMSU website\n",
        "- **Text Processing**: Split documents into manageable chunks\n",
        "- **Vector Storage**: Create embeddings for similarity search\n",
        "- **Context Retrieval**: Find relevant information for questions\n",
        "- **Answer Generation**: Use AI to generate responses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NWMSURAGChatbot:\n",
        "    \"\"\"RAG Chatbot for NWMSU MS-ACS Program - Built by Students\"\"\"\n",
        "    \n",
        "    def __init__(self, use_gpu=False):\n",
        "        print(\"üöÄ Initializing your RAG Chatbot...\")\n",
        "        print(\"üìö This chatbot will help students learn about NWMSU MS-ACS program\")\n",
        "        \n",
        "        self.device = \"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"üì± Using device: {self.device}\")\n",
        "        \n",
        "        # Initialize embeddings - these convert text to numbers for similarity search\n",
        "        print(\"üî§ Loading text embeddings...\")\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "            model_kwargs={'device': self.device}\n",
        "        )\n",
        "        \n",
        "        # Initialize the AI language model\n",
        "        print(\"üß† Loading AI language model...\")\n",
        "        self.llm = self._setup_llm()\n",
        "        \n",
        "        print(\"‚úÖ Chatbot initialized successfully!\")\n",
        "    \n",
        "    def _setup_llm(self):\n",
        "        \"\"\"Setup the AI language model that will generate answers\"\"\"\n",
        "        print(\"    üì• Downloading AI model... (this may take a few minutes)\")\n",
        "        model_id = \"google/flan-t5-base\"  # A good model for question-answering\n",
        "        \n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
        "            low_cpu_mem_usage=True\n",
        "        )\n",
        "        \n",
        "        # Create a pipeline for text generation\n",
        "        pipe = pipeline(\n",
        "            \"text2text-generation\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_length=512,\n",
        "            device=0 if self.device == \"cuda\" else -1\n",
        "        )\n",
        "        \n",
        "        return HuggingFacePipeline(pipeline=pipe)\n",
        "    \n",
        "    def _setup_neo4j(self):\n",
        "        \"\"\"Setup Neo4j connection\"\"\"\n",
        "        print(\"üóÑÔ∏è Setting up Neo4j connection...\")\n",
        "        \n",
        "        # Neo4j connection details (you can modify these)\n",
        "        NEO4J_URI = \"neo4j+s://813403d3.databases.neo4j.io\"\n",
        "        NEO4J_USERNAME = \"neo4j\"\n",
        "        NEO4J_PASSWORD = \"4EfVPpL8RGgaSXTN1rudzLxMygGnihSAMtblyskNWz8\"\n",
        "        \n",
        "        try:\n",
        "            # Test connection\n",
        "            driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
        "            with driver.session() as session:\n",
        "                session.run(\"RETURN 1\")\n",
        "            \n",
        "            # Create LangChain Neo4j graph\n",
        "            graph = Neo4jGraph(\n",
        "                url=NEO4J_URI,\n",
        "                username=NEO4J_USERNAME,\n",
        "                password=NEO4J_PASSWORD\n",
        "            )\n",
        "            \n",
        "            print(\"‚úÖ Neo4j connection established\")\n",
        "            return graph\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Neo4j connection failed: {e}\")\n",
        "            print(\"üîÑ Falling back to FAISS-only mode\")\n",
        "            return None\n",
        "    \n",
        "    def load_data(self):\n",
        "        \"\"\"Load information from NWMSU website about the MS-ACS program\"\"\"\n",
        "        print(\"üì• Loading data from NWMSU website...\")\n",
        "        print(\"    üåê Scraping web pages for MS-ACS program information...\")\n",
        "        \n",
        "        # URLs of NWMSU pages with MS-ACS program information\n",
        "        urls = [\n",
        "            \"https://www.nwmissouri.edu/csis/msacs/\",\n",
        "            \"https://www.nwmissouri.edu/csis/msacs/about.htm\",\n",
        "            \"https://www.nwmissouri.edu/academics/graduate/masters/applied-computer-science.htm\",\n",
        "            \"https://www.nwmissouri.edu/csis/msacs/apply/index.htm\",\n",
        "            \"https://www.nwmissouri.edu/csis/msacs/courses.htm\",\n",
        "            \"https://www.nwmissouri.edu/csis/msacs/FAQs.htm\",\n",
        "            \"https://www.nwmissouri.edu/csis/msacs/contact.htm\"\n",
        "        ]\n",
        "        \n",
        "        # Use LangChain's web loader to get the content\n",
        "        loader = WebBaseLoader(urls)\n",
        "        loader.requests_kwargs = {'verify': False}  # Handle SSL issues\n",
        "        docs = loader.load()\n",
        "        \n",
        "        # Split large documents into smaller chunks for better processing\n",
        "        print(\"    ‚úÇÔ∏è Splitting documents into manageable chunks...\")\n",
        "        splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=800,    # Each chunk will be ~800 characters\n",
        "            chunk_overlap=100  # Overlap to maintain context\n",
        "        )\n",
        "        chunks = splitter.split_documents(docs)\n",
        "        \n",
        "        print(f\"‚úÖ Successfully loaded {len(chunks)} document chunks\")\n",
        "        print(f\"üìÑ Total pages processed: {len(docs)}\")\n",
        "        return chunks\n",
        "    \n",
        "    def create_vector_store(self, documents):\n",
        "        \"\"\"Create a vector database for similarity search\"\"\"\n",
        "        print(\"üîç Creating vector database...\")\n",
        "        print(\"    üßÆ Converting text to numerical vectors...\")\n",
        "        \n",
        "        # Create FAISS vector store - this will store our document embeddings\n",
        "        vector_store = FAISS.from_documents(documents, self.embeddings)\n",
        "        \n",
        "        print(\"‚úÖ Vector database created successfully!\")\n",
        "        print(\"    üìä Your chatbot can now find similar documents quickly\")\n",
        "        return vector_store\n",
        "    \n",
        "    def retrieve_context(self, question: str, vector_store, k: int = 3) -> str:\n",
        "        \"\"\"Find relevant information for the user's question\"\"\"\n",
        "        print(f\"üîç Searching for relevant information...\")\n",
        "        print(f\"    ‚ùì Question: '{question}'\")\n",
        "        \n",
        "        # Use similarity search to find the most relevant documents\n",
        "        docs = vector_store.similarity_search(question, k=k)\n",
        "        \n",
        "        # Combine the retrieved documents into context\n",
        "        context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "        \n",
        "        print(f\"    üìÑ Found {len(docs)} relevant documents\")\n",
        "        print(f\"    üìù Context length: {len(context)} characters\")\n",
        "        return context\n",
        "    \n",
        "    def create_qa_chain(self, vector_store):\n",
        "        \"\"\"Create the question-answering system\"\"\"\n",
        "        print(\"‚öôÔ∏è Setting up question-answering system...\")\n",
        "        \n",
        "        def retriever_func(question: str) -> str:\n",
        "            return self.retrieve_context(question, vector_store)\n",
        "        \n",
        "        # Template for how the AI should answer questions\n",
        "        template = \"\"\"Answer the question based on the context below. Be specific and accurate.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer concisely:\"\"\"\n",
        "        \n",
        "        prompt = ChatPromptTemplate.from_template(template)\n",
        "        \n",
        "        # Create the complete chain: retrieve context -> generate answer\n",
        "        chain = (\n",
        "            RunnableParallel({\n",
        "                \"context\": lambda x: retriever_func(x[\"question\"]),\n",
        "                \"question\": lambda x: x[\"question\"]\n",
        "            })\n",
        "            | prompt\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "        \n",
        "        print(\"‚úÖ Question-answering system ready!\")\n",
        "        return chain\n",
        "    \n",
        "    def setup(self):\n",
        "        \"\"\"Setup the complete RAG chatbot system\"\"\"\n",
        "        print(\"üîß Setting up your RAG chatbot...\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        # Step 1: Load data from NWMSU website\n",
        "        documents = self.load_data()\n",
        "        \n",
        "        # Step 2: Create vector database\n",
        "        self.vector_store = self.create_vector_store(documents)\n",
        "        \n",
        "        # Step 3: Create question-answering system\n",
        "        self.qa_chain = self.create_qa_chain(self.vector_store)\n",
        "        \n",
        "        print(\"\\nüéâ Your RAG chatbot is ready!\")\n",
        "        print(\"üí¨ You can now ask questions about the NWMSU MS-ACS program!\")\n",
        "    \n",
        "    def ask_question(self, question: str) -> str:\n",
        "        \"\"\"Ask a question and get an answer\"\"\"\n",
        "        try:\n",
        "            print(f\"\\nü§ñ Processing your question...\")\n",
        "            answer = self.qa_chain.invoke({\"question\": question})\n",
        "            return answer\n",
        "        except Exception as e:\n",
        "            return f\"Sorry, I encountered an error: {str(e)}\"\n",
        "    \n",
        "    def ask_with_context(self, question: str) -> Tuple[str, str]:\n",
        "        \"\"\"Ask a question and return both answer and context (for learning purposes)\"\"\"\n",
        "        try:\n",
        "            # Get context that was used to answer the question\n",
        "            context = self.retrieve_context(question, self.vector_store)\n",
        "            \n",
        "            # Get the answer\n",
        "            answer = self.qa_chain.invoke({\"question\": question})\n",
        "            \n",
        "            return answer, context\n",
        "        except Exception as e:\n",
        "            return f\"Error: {str(e)}\", f\"Context retrieval failed: {str(e)}\"\n",
        "\n",
        "print(\"‚úÖ Your RAG Chatbot class is ready!\")\n",
        "print(\"üéì Students can now build their own chatbot!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Initialize the RAG System\n",
        "\n",
        "Let's create and setup our RAG chatbot. This will take a few minutes as it downloads models and processes data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize your RAG chatbot\n",
        "print(\"üöÄ Creating your RAG chatbot...\")\n",
        "chatbot = NWMSURAGChatbot(use_gpu=False)\n",
        "\n",
        "# Setup the complete system (this will take a few minutes)\n",
        "chatbot.setup()\n",
        "\n",
        "print(\"\\nüéâ Congratulations! Your RAG chatbot is ready!\")\n",
        "print(\"üí¨ You can now ask questions about the NWMSU MS-ACS program!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Step 4: Test Your RAG Chatbot!\n",
        "\n",
        "Now let's test your chatbot by asking questions about the NWMSU MS-ACS program. You'll see how RAG works by showing the context that was retrieved before generating each answer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def demo_rag(question: str):\n",
        "    \"\"\"Test your RAG chatbot and see how it works\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"‚ùì QUESTION: {question}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Get answer and context from your chatbot\n",
        "    answer, context = chatbot.ask_with_context(question)\n",
        "    \n",
        "    # Show the context that was retrieved (this is the RAG part!)\n",
        "    print(f\"\\nüîç CONTEXT RETRIEVED BY YOUR CHATBOT:\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"{context[:500]}...\" if len(context) > 500 else context)\n",
        "    print(f\"\\nüìä Context length: {len(context)} characters\")\n",
        "    \n",
        "    # Show the final answer\n",
        "    print(f\"\\nü§ñ YOUR CHATBOT'S ANSWER:\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"{answer}\")\n",
        "    \n",
        "    return answer, context\n",
        "\n",
        "print(\"‚úÖ Demo function ready!\")\n",
        "print(\"üéì Now you can test your RAG chatbot!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Step 5: Test Your Chatbot with Sample Questions\n",
        "\n",
        "Let's test your RAG chatbot with some common questions about the MS-ACS program. Watch how it retrieves context before answering!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Question 1: GPA Requirements\n",
        "print(\"üéì Testing your chatbot with a GPA question...\")\n",
        "demo_rag(\"What is the minimum GPA required for MS-ACS program?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Question 2: TOEFL Requirements\n",
        "print(\"\\nüéì Testing your chatbot with a TOEFL question...\")\n",
        "demo_rag(\"What are the TOEFL score requirements?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Question 3: Program Advisor\n",
        "print(\"\\nüéì Testing your chatbot with an advisor question...\")\n",
        "demo_rag(\"Who is the program advisor for MS-ACS?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Question 4: Duolingo Requirements\n",
        "print(\"\\nüéì Testing your chatbot with a Duolingo question...\")\n",
        "demo_rag(\"What is the Duolingo score requirement?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéÆ Step 6: Interactive Chatbot Interface\n",
        "\n",
        "Now you can ask your own questions! Use the interface below to test your RAG chatbot with any questions about the MS-ACS program.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive chatbot interface for students\n",
        "def interactive_rag(question):\n",
        "    if question.strip():\n",
        "        return demo_rag(question)\n",
        "    else:\n",
        "        print(\"Please enter a question!\")\n",
        "\n",
        "# Create an interactive interface for your chatbot\n",
        "print(\"üéì Create your own chatbot interface!\")\n",
        "print(\"üí¨ Ask any question about the NWMSU MS-ACS program:\")\n",
        "\n",
        "question_widget = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Ask a question about MS-ACS program... (e.g., \"What courses are offered?\")',\n",
        "    description='Your Question:',\n",
        "    layout=widgets.Layout(width='100%', height='100px')\n",
        ")\n",
        "\n",
        "button = widgets.Button(description=\"Ask Your Chatbot\", button_style='success')\n",
        "\n",
        "def on_button_click(b):\n",
        "    if question_widget.value.strip():\n",
        "        print(f\"\\nüéì Student Question: {question_widget.value}\")\n",
        "        demo_rag(question_widget.value)\n",
        "    else:\n",
        "        print(\"Please enter a question!\")\n",
        "\n",
        "button.on_click(on_button_click)\n",
        "\n",
        "# Display the interactive interface\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>ü§ñ Your RAG Chatbot Interface</h3>\"),\n",
        "    question_widget, \n",
        "    button\n",
        "]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üóÑÔ∏è Neo4j Graph Database Features\n",
        "\n",
        "Let's explore the advanced features that Neo4j brings to our RAG system:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display graph statistics\n",
        "def show_graph_stats():\n",
        "    \"\"\"Display Neo4j graph statistics\"\"\"\n",
        "    print(\"üìä Neo4j Graph Statistics:\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    stats = chatbot.get_graph_stats()\n",
        "    for stat in stats:\n",
        "        print(f\"‚Ä¢ {stat['label']}: {stat['count']}\")\n",
        "    \n",
        "    print(\"\\nüîç Graph Structure:\")\n",
        "    print(\"Program ‚Üí Requirements ‚Üí Faculty\")\n",
        "    print(\"   ‚Üì           ‚Üì          ‚Üì\")\n",
        "    print(\"MS-ACS    GPA, TOEFL   Dr. Ajay Bandi\")\n",
        "    print(\"          Duolingo, IELTS\")\n",
        "\n",
        "show_graph_stats()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate structured vs unstructured retrieval\n",
        "def compare_retrieval_methods(question: str):\n",
        "    \"\"\"Compare structured (Neo4j) vs unstructured (vector) retrieval\"\"\"\n",
        "    print(f\"\\nüîç RETRIEVAL COMPARISON\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Question: {question}\")\n",
        "    \n",
        "    # Structured retrieval (Neo4j)\n",
        "    print(f\"\\nüóÑÔ∏è STRUCTURED RETRIEVAL (Neo4j):\")\n",
        "    print(f\"{'='*40}\")\n",
        "    structured = chatbot.retrieve_structured_context(question)\n",
        "    print(f\"Result: {structured}\")\n",
        "    \n",
        "    # Unstructured retrieval (Vector)\n",
        "    print(f\"\\nüìÑ UNSTRUCTURED RETRIEVAL (Vector):\")\n",
        "    print(f\"{'='*40}\")\n",
        "    docs = chatbot.vector_store.similarity_search(question, k=2)\n",
        "    unstructured = \"\\n\\n\".join([doc.page_content[:200] + \"...\" for doc in docs])\n",
        "    print(f\"Result: {unstructured}\")\n",
        "    \n",
        "    # Combined (RAG)\n",
        "    print(f\"\\nü§ñ COMBINED RAG RETRIEVAL:\")\n",
        "    print(f\"{'='*40}\")\n",
        "    answer, context = chatbot.ask_with_context(question)\n",
        "    print(f\"Answer: {answer}\")\n",
        "    print(f\"Context length: {len(context)} characters\")\n",
        "\n",
        "# Test the comparison\n",
        "compare_retrieval_methods(\"What are the admission requirements?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Advanced Neo4j RAG Features\n",
        "\n",
        "### üîç **What Makes Neo4j RAG Special:**\n",
        "\n",
        "1. **Structured Data**: Neo4j stores entities and relationships\n",
        "2. **Graph Queries**: Cypher queries for precise data retrieval\n",
        "3. **Hybrid Retrieval**: Combines structured + unstructured data\n",
        "4. **Relationship Awareness**: Understands connections between entities\n",
        "5. **Precise Answers**: More accurate responses with structured context\n",
        "\n",
        "### üõ†Ô∏è **Technical Advantages:**\n",
        "\n",
        "- **Entity Recognition**: Automatically extracts Program, Requirements, Faculty\n",
        "- **Relationship Mapping**: Creates connections between entities\n",
        "- **Structured Queries**: Precise data retrieval with Cypher\n",
        "- **Hybrid Context**: Combines graph + vector search\n",
        "- **Better Accuracy**: More precise answers with structured data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced Neo4j query demonstration\n",
        "def demonstrate_neo4j_queries():\n",
        "    \"\"\"Demonstrate different types of Neo4j queries\"\"\"\n",
        "    if not chatbot.graph:\n",
        "        print(\"‚ö†Ô∏è Neo4j not available for advanced queries\")\n",
        "        return\n",
        "    \n",
        "    print(\"üîç NEO4J QUERY DEMONSTRATIONS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Query 1: Get all requirements\n",
        "    print(\"\\n1Ô∏è‚É£ All Requirements:\")\n",
        "    result = chatbot.graph.query(\"\"\"\n",
        "        MATCH (p:Program)-[:HAS_REQUIREMENT]->(r:Requirement)\n",
        "        RETURN r.name, r.value, r.description\n",
        "    \"\"\")\n",
        "    for row in result:\n",
        "        print(f\"‚Ä¢ {row['r.name']}: {row['r.value']} - {row['r.description']}\")\n",
        "    \n",
        "    # Query 2: Get faculty information\n",
        "    print(\"\\n2Ô∏è‚É£ Faculty Information:\")\n",
        "    result = chatbot.graph.query(\"\"\"\n",
        "        MATCH (f:Faculty)-[:ADVISES]->(p:Program)\n",
        "        RETURN f.name, f.role, f.email\n",
        "    \"\"\")\n",
        "    for row in result:\n",
        "        print(f\"‚Ä¢ {row['f.name']} ({row['f.role']}): {row['f.email']}\")\n",
        "    \n",
        "    # Query 3: Get program structure\n",
        "    print(\"\\n3Ô∏è‚É£ Program Structure:\")\n",
        "    result = chatbot.graph.query(\"\"\"\n",
        "        MATCH (p:Program)-[r]->(n)\n",
        "        RETURN type(r) as relationship, count(n) as count\n",
        "        ORDER BY count DESC\n",
        "    \"\"\")\n",
        "    for row in result:\n",
        "        print(f\"‚Ä¢ {row['relationship']}: {row['count']} entities\")\n",
        "\n",
        "demonstrate_neo4j_queries()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö How RAG Works - Educational Explanation\n",
        "\n",
        "### üîç **Retrieval-Augmented Generation (RAG) Process:**\n",
        "\n",
        "1. **üì• Data Ingestion**: Load documents from NWMSU website\n",
        "2. **‚úÇÔ∏è Text Splitting**: Break documents into manageable chunks\n",
        "3. **üî§ Embedding Creation**: Convert text chunks to numerical vectors\n",
        "4. **üóÑÔ∏è Vector Storage**: Store embeddings in a searchable database\n",
        "5. **üîç Context Retrieval**: Find relevant chunks for user questions\n",
        "6. **ü§ñ Answer Generation**: Use retrieved context to generate accurate answers\n",
        "\n",
        "### üéØ **Why RAG is Important:**\n",
        "\n",
        "- **üéØ Accuracy**: Provides specific, factual information\n",
        "- **üìö Knowledge Base**: Can access up-to-date information\n",
        "- **üîç Transparency**: Shows what information was used\n",
        "- **üéì Educational**: Demonstrates how AI uses context\n",
        "\n",
        "### üõ†Ô∏è **Technical Components:**\n",
        "\n",
        "- **Embeddings**: `sentence-transformers/all-MiniLM-L6-v2`\n",
        "- **LLM**: `google/flan-t5-base`\n",
        "- **Vector Store**: FAISS (Facebook AI Similarity Search)\n",
        "- **Framework**: LangChain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öñÔ∏è RAG vs Traditional AI Comparison\n",
        "\n",
        "Let's compare how RAG provides better answers than traditional AI:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_rag_vs_traditional(question: str):\n",
        "    \"\"\"Compare RAG vs traditional AI responses\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"‚ùì QUESTION: {question}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    # RAG Response\n",
        "    print(f\"\\nüîç RAG RESPONSE (with context):\")\n",
        "    print(f\"{'='*40}\")\n",
        "    rag_answer, context = chatbot.ask_with_context(question)\n",
        "    print(f\"Answer: {rag_answer}\")\n",
        "    print(f\"Context used: {len(context)} characters\")\n",
        "    \n",
        "    # Traditional AI (without context)\n",
        "    print(f\"\\nü§ñ TRADITIONAL AI (no context):\")\n",
        "    print(f\"{'='*40}\")\n",
        "    traditional_answer = chatbot.llm.invoke(question)\n",
        "    print(f\"Answer: {traditional_answer}\")\n",
        "    print(f\"Context used: 0 characters (no retrieval)\")\n",
        "    \n",
        "    print(f\"\\nüìä COMPARISON:\")\n",
        "    print(f\"- RAG uses {len(context)} characters of specific context\")\n",
        "    print(f\"- Traditional AI relies only on training data\")\n",
        "    print(f\"- RAG provides more accurate, up-to-date information\")\n",
        "\n",
        "# Example comparison\n",
        "compare_rag_vs_traditional(\"What is the minimum GPA required for MS-ACS program?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéì Educational Insights\n",
        "\n",
        "### üîç **What Students Learn from This Demo:**\n",
        "\n",
        "1. **RAG Architecture**: How retrieval and generation work together\n",
        "2. **Vector Embeddings**: How text is converted to numerical representations\n",
        "3. **Similarity Search**: How relevant documents are found\n",
        "4. **Context Injection**: How retrieved context improves AI responses\n",
        "5. **Transparency**: How to show what information was used\n",
        "\n",
        "### üõ†Ô∏è **Technical Skills Demonstrated:**\n",
        "\n",
        "- **LangChain**: Modern framework for LLM applications\n",
        "- **Vector Databases**: FAISS for efficient similarity search\n",
        "- **Embeddings**: Sentence transformers for semantic understanding\n",
        "- **Document Processing**: Web scraping and text chunking\n",
        "- **Interactive UI**: Jupyter widgets for user interaction\n",
        "\n",
        "### üéØ **Real-World Applications:**\n",
        "\n",
        "- **Customer Support**: Company-specific knowledge bases\n",
        "- **Educational**: Course-specific information systems\n",
        "- **Research**: Academic paper question-answering\n",
        "- **Business**: Internal documentation systems\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Conclusion\n",
        "\n",
        "### ‚úÖ **What We Accomplished:**\n",
        "\n",
        "1. **Built a complete RAG system** from scratch\n",
        "2. **Demonstrated context retrieval** in real-time\n",
        "3. **Showed transparency** in AI responses\n",
        "4. **Created an interactive demo** for students\n",
        "5. **Explained the technical concepts** behind RAG\n",
        "\n",
        "### üöÄ **Next Steps for Students:**\n",
        "\n",
        "1. **Experiment with different questions**\n",
        "2. **Try different embedding models**\n",
        "3. **Modify the context retrieval parameters**\n",
        "4. **Add new data sources**\n",
        "5. **Implement advanced RAG techniques**\n",
        "\n",
        "### üìö **Key Takeaways:**\n",
        "\n",
        "- **RAG provides better answers** by using relevant context\n",
        "- **Transparency is important** for AI systems\n",
        "- **Vector embeddings** enable semantic search\n",
        "- **Context retrieval** is the key to RAG success\n",
        "- **Interactive demos** help students understand complex concepts\n",
        "\n",
        "---\n",
        "\n",
        "**üéì This notebook demonstrates how to build and understand RAG systems for educational purposes!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final interactive demo\n",
        "print(\"üéâ RAG Demo Complete!\")\n",
        "print(\"\\nTry asking your own questions about the MS-ACS program:\")\n",
        "print(\"- What are the admission requirements?\")\n",
        "print(\"- Who can I contact for more information?\")\n",
        "print(\"- What courses are available?\")\n",
        "print(\"- What is the program duration?\")\n",
        "print(\"\\nUse the interactive widget above to ask questions!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
